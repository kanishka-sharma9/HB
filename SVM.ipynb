{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfb74062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature selection...\n",
      "\n",
      "Selected Features:\n",
      "1. HALSTEAD_CONTENT\n",
      "2. NUMBER_OF_LINES\n",
      "\n",
      "Model Performance Metrics:\n",
      "Accuracy: 0.8485\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F-measure: 0.0000\n",
      "AUC Score: 0.3855\n",
      "\n",
      "Confusion Matrix:\n",
      "[True Negatives  False Positives]\n",
      "[False Negatives True Positives]\n",
      "[[84  2]\n",
      " [13  0]]\n",
      "\n",
      "Feature Importance Analysis:\n",
      "HALSTEAD_CONTENT: Original index 2\n",
      "NUMBER_OF_LINES: Original index 6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class HoneyBadgerFeatureSelection:\n",
    "    def __init__(self, n_features_to_select=5, max_iter=50, population_size=20):\n",
    "        self.n_features = n_features_to_select\n",
    "        self.max_iter = max_iter\n",
    "        self.population_size = population_size\n",
    "        self.best_features = None\n",
    "        self.best_fitness = float('-inf')\n",
    "    \n",
    "    def fitness_function(self, selected_features, X, y, classifier):\n",
    "        if np.sum(selected_features) == 0:\n",
    "            return float('-inf')\n",
    "            \n",
    "        X_selected = X[:, selected_features == 1]\n",
    "        try:\n",
    "            classifier.fit(X_selected, y)\n",
    "            y_pred = classifier.predict(X_selected)\n",
    "            return accuracy_score(y, y_pred)\n",
    "        except:\n",
    "            return float('-inf')\n",
    "    \n",
    "    def honey_badger_movement(self, current_position, best_position):\n",
    "        r = np.random.random()\n",
    "        if r < 0.5:\n",
    "            return np.where(np.random.random(len(current_position)) < 0.3,\n",
    "                          1 - current_position,\n",
    "                          current_position)\n",
    "        else:\n",
    "            return np.where(np.random.random(len(current_position)) < 0.5,\n",
    "                          best_position,\n",
    "                          current_position)\n",
    "    \n",
    "    def fit(self, X, y, classifier):\n",
    "        n_total_features = X.shape[1]\n",
    "        population = np.random.randint(2, size=(self.population_size, n_total_features))\n",
    "        for i in range(self.population_size):\n",
    "            if np.sum(population[i]) < self.n_features:\n",
    "                random_indices = np.random.choice(\n",
    "                    n_total_features, \n",
    "                    self.n_features - np.sum(population[i]),\n",
    "                    replace=False\n",
    "                )\n",
    "                population[i, random_indices] = 1\n",
    "        \n",
    "        global_best_position = None\n",
    "        global_best_fitness = float('-inf')\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            fitness_values = np.array([\n",
    "                self.fitness_function(position, X, y, classifier)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            current_best_idx = np.argmax(fitness_values)\n",
    "            if fitness_values[current_best_idx] > global_best_fitness:\n",
    "                global_best_fitness = fitness_values[current_best_idx]\n",
    "                global_best_position = population[current_best_idx].copy()\n",
    "            \n",
    "            new_population = np.array([\n",
    "                self.honey_badger_movement(position, global_best_position)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            population = new_population\n",
    "        \n",
    "        self.best_features = global_best_position\n",
    "        self.best_fitness = global_best_fitness\n",
    "        return self\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    # Read training and testing data\n",
    "    train_data = pd.read_csv('Training Data/CM1_FS_TrainData.csv')\n",
    "    test_data = pd.read_csv('Testing Data/CM1_FS_TestData.csv')\n",
    "    \n",
    "    # Separate features and target for both datasets\n",
    "    X_train = train_data.drop('Defective', axis=1)\n",
    "    y_train = train_data['Defective']\n",
    "    X_test = test_data.drop('Defective', axis=1)\n",
    "    y_test = test_data['Defective']\n",
    "    \n",
    "    # Convert target to numeric\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test, n_features=5):\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Initialize SVM\n",
    "    svm = SVC(kernel='rbf', random_state=42, probability=True)\n",
    "    \n",
    "    # Feature selection using training data\n",
    "    print(\"Starting feature selection...\")\n",
    "    hb = HoneyBadgerFeatureSelection(n_features_to_select=n_features)\n",
    "    hb.fit(X_train_scaled, y_train, svm)\n",
    "    \n",
    "    # Get selected features\n",
    "    selected_features = np.where(hb.best_features == 1)[0]\n",
    "    selected_feature_names = X_train.columns[selected_features].tolist()\n",
    "    \n",
    "    # Train final model with selected features\n",
    "    X_train_selected = X_train_scaled[:, selected_features]\n",
    "    X_test_selected = X_test_scaled[:, selected_features]\n",
    "    \n",
    "    final_svm = SVC(kernel='rbf', random_state=42, probability=True)\n",
    "    final_svm.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    y_pred = final_svm.predict(X_test_selected)\n",
    "    y_pred_proba = final_svm.predict_proba(X_test_selected)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f_measure = f1_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'model': final_svm,\n",
    "        'selected_features': selected_feature_names,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f_measure': f_measure,\n",
    "        'auc_score': auc_score,\n",
    "        'confusion_matrix': conf_matrix,\n",
    "        'scaler': scaler,\n",
    "        'selected_indices': selected_features\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    X_train, X_test, y_train, y_test = load_and_preprocess_data()\n",
    "    \n",
    "    # Train model and get results\n",
    "    results = train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test, n_features=5)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nSelected Features:\")\n",
    "    for i, feature in enumerate(results['selected_features'], 1):\n",
    "        print(f\"{i}. {feature}\")\n",
    "    \n",
    "    print(f\"\\nModel Performance Metrics:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {results['precision']:.4f}\")\n",
    "    print(f\"Recall: {results['recall']:.4f}\")\n",
    "    print(f\"F-measure: {results['f_measure']:.4f}\")\n",
    "    print(f\"AUC Score: {results['auc_score']:.4f}\")\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"[True Negatives  False Positives]\")\n",
    "    print(\"[False Negatives True Positives]\")\n",
    "    print(results['confusion_matrix'])\n",
    "    \n",
    "    # Additional analysis of selected features\n",
    "    print(\"\\nFeature Importance Analysis:\")\n",
    "    for feature, idx in zip(results['selected_features'], results['selected_indices']):\n",
    "        print(f\"{feature}: Original index {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c84c73f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature selection...\n",
      "\n",
      "Selected Features:\n",
      "Number of features selected: 4\n",
      "1. LOC_COMMENTS\n",
      "2. DESIGN_COMPLEXITY\n",
      "3. HALSTEAD_EFFORT\n",
      "4. MULTIPLE_CONDITION_COUNT\n",
      "\n",
      "Model Performance Metrics:\n",
      "Accuracy: 0.6053\n",
      "Precision: 0.4000\n",
      "Recall: 0.3077\n",
      "F-measure: 0.3478\n",
      "AUC Score: 0.6185\n",
      "\n",
      "Confusion Matrix:\n",
      "[True Negatives  False Positives]\n",
      "[False Negatives True Positives]\n",
      "[[19  6]\n",
      " [ 9  4]]\n",
      "\n",
      "Feature Importance Analysis:\n",
      "LOC_COMMENTS: Original index 1\n",
      "DESIGN_COMPLEXITY: Original index 2\n",
      "HALSTEAD_EFFORT: Original index 6\n",
      "MULTIPLE_CONDITION_COUNT: Original index 7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class HoneyBadgerFeatureSelection:\n",
    "    def __init__(self, max_iter=50, population_size=20):\n",
    "        self.max_iter = max_iter\n",
    "        self.population_size = population_size\n",
    "        self.best_features = None\n",
    "        self.best_fitness = float('-inf')\n",
    "    \n",
    "    def fitness_function(self, selected_features, X, y, classifier):\n",
    "        if np.sum(selected_features) == 0:\n",
    "            return float('-inf')\n",
    "            \n",
    "        X_selected = X[:, selected_features == 1]\n",
    "        try:\n",
    "            classifier.fit(X_selected, y)\n",
    "            y_pred = classifier.predict(X_selected)\n",
    "            # Modified fitness function to balance accuracy and feature count\n",
    "            accuracy = accuracy_score(y, y_pred)\n",
    "            feature_penalty = 0.01 * np.sum(selected_features) / len(selected_features)\n",
    "            return accuracy - feature_penalty\n",
    "        except:\n",
    "            return float('-inf')\n",
    "    \n",
    "    def honey_badger_movement(self, current_position, best_position):\n",
    "        r = np.random.random()\n",
    "        if r < 0.5:\n",
    "            # Exploration phase: flip bits with 30% probability\n",
    "            return np.where(np.random.random(len(current_position)) < 0.3,\n",
    "                          1 - current_position,\n",
    "                          current_position)\n",
    "        else:\n",
    "            # Exploitation phase: follow best position with 50% probability\n",
    "            return np.where(np.random.random(len(current_position)) < 0.5,\n",
    "                          best_position,\n",
    "                          current_position)\n",
    "    \n",
    "    def fit(self, X, y, classifier):\n",
    "        n_total_features = X.shape[1]\n",
    "        # Initialize population with random binary vectors\n",
    "        population = np.random.randint(2, size=(self.population_size, n_total_features))\n",
    "        \n",
    "        global_best_position = None\n",
    "        global_best_fitness = float('-inf')\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            fitness_values = np.array([\n",
    "                self.fitness_function(position, X, y, classifier)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            current_best_idx = np.argmax(fitness_values)\n",
    "            if fitness_values[current_best_idx] > global_best_fitness:\n",
    "                global_best_fitness = fitness_values[current_best_idx]\n",
    "                global_best_position = population[current_best_idx].copy()\n",
    "            \n",
    "            new_population = np.array([\n",
    "                self.honey_badger_movement(position, global_best_position)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            population = new_population\n",
    "        \n",
    "        self.best_features = global_best_position\n",
    "        self.best_fitness = global_best_fitness\n",
    "        return self\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    # Read training and testing data\n",
    "    train_data = pd.read_csv('Training Data/MC2_FS_TrainData.csv')\n",
    "    test_data = pd.read_csv('Testing Data/MC2_FS_TestData.csv')\n",
    "    \n",
    "    # Separate features and target for both datasets\n",
    "    X_train = train_data.drop('Defective', axis=1)\n",
    "    y_train = train_data['Defective']\n",
    "    X_test = test_data.drop('Defective', axis=1)\n",
    "    y_test = test_data['Defective']\n",
    "    \n",
    "    # Convert target to numeric\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test):\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Initialize SVM\n",
    "    svm = SVC(kernel='rbf', random_state=42, probability=True)\n",
    "    \n",
    "    # Feature selection using training data\n",
    "    print(\"Starting feature selection...\")\n",
    "    hb = HoneyBadgerFeatureSelection()\n",
    "    hb.fit(X_train_scaled, y_train, svm)\n",
    "    \n",
    "    # Get selected features\n",
    "    selected_features = np.where(hb.best_features == 1)[0]\n",
    "    selected_feature_names = X_train.columns[selected_features].tolist()\n",
    "    \n",
    "    # Train final model with selected features\n",
    "    X_train_selected = X_train_scaled[:, selected_features]\n",
    "    X_test_selected = X_test_scaled[:, selected_features]\n",
    "    \n",
    "    final_svm = SVC(kernel='rbf', random_state=42, probability=True)\n",
    "    final_svm.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    y_pred = final_svm.predict(X_test_selected)\n",
    "    y_pred_proba = final_svm.predict_proba(X_test_selected)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f_measure = f1_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'model': final_svm,\n",
    "        'selected_features': selected_feature_names,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f_measure': f_measure,\n",
    "        'auc_score': auc_score,\n",
    "        'confusion_matrix': conf_matrix,\n",
    "        'scaler': scaler,\n",
    "        'selected_indices': selected_features\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    X_train, X_test, y_train, y_test = load_and_preprocess_data()\n",
    "    \n",
    "    # Train model and get results\n",
    "    results = train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nSelected Features:\")\n",
    "    print(f\"Number of features selected: {len(results['selected_features'])}\")\n",
    "    for i, feature in enumerate(results['selected_features'], 1):\n",
    "        print(f\"{i}. {feature}\")\n",
    "    \n",
    "    print(f\"\\nModel Performance Metrics:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {results['precision']:.4f}\")\n",
    "    print(f\"Recall: {results['recall']:.4f}\")\n",
    "    print(f\"F-measure: {results['f_measure']:.4f}\")\n",
    "    print(f\"AUC Score: {results['auc_score']:.4f}\")\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"[True Negatives  False Positives]\")\n",
    "    print(\"[False Negatives True Positives]\")\n",
    "    print(results['confusion_matrix'])\n",
    "    \n",
    "    # Additional analysis of selected features\n",
    "    print(\"\\nFeature Importance Analysis:\")\n",
    "    for feature, idx in zip(results['selected_features'], results['selected_indices']):\n",
    "        print(f\"{feature}: Original index {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c701ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature selection...\n",
      "\n",
      "Selected Features:\n",
      "1. CALL_PAIRS\n",
      "2. EDGE_COUNT\n",
      "3. HALSTEAD_LENGTH\n",
      "4. NODE_COUNT\n",
      "5. LOC_TOTAL\n",
      "\n",
      "Model Performance Metrics:\n",
      "Accuracy: 0.9067\n",
      "Precision: 1.0000\n",
      "Recall: 0.1250\n",
      "F-measure: 0.2222\n",
      "AUC Score: 0.7631\n",
      "\n",
      "Confusion Matrix:\n",
      "[True Negatives  False Positives]\n",
      "[False Negatives True Positives]\n",
      "[[67  0]\n",
      " [ 7  1]]\n",
      "\n",
      "Feature Importance Analysis:\n",
      "CALL_PAIRS: Original index 0\n",
      "EDGE_COUNT: Original index 2\n",
      "HALSTEAD_LENGTH: Original index 4\n",
      "NODE_COUNT: Original index 5\n",
      "LOC_TOTAL: Original index 7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class HoneyBadgerFeatureSelection:\n",
    "    def __init__(self, n_features_to_select=5, max_iter=50, population_size=20):\n",
    "        self.n_features = n_features_to_select\n",
    "        self.max_iter = max_iter\n",
    "        self.population_size = population_size\n",
    "        self.best_features = None\n",
    "        self.best_fitness = float('-inf')\n",
    "    \n",
    "    def fitness_function(self, selected_features, X, y, classifier):\n",
    "        if np.sum(selected_features) == 0:\n",
    "            return float('-inf')\n",
    "            \n",
    "        X_selected = X[:, selected_features == 1]\n",
    "        try:\n",
    "            classifier.fit(X_selected, y)\n",
    "            y_pred = classifier.predict(X_selected)\n",
    "            return accuracy_score(y, y_pred)\n",
    "        except:\n",
    "            return float('-inf')\n",
    "    \n",
    "    def honey_badger_movement(self, current_position, best_position):\n",
    "        r = np.random.random()\n",
    "        if r < 0.5:\n",
    "            return np.where(np.random.random(len(current_position)) < 0.3,\n",
    "                          1 - current_position,\n",
    "                          current_position)\n",
    "        else:\n",
    "            return np.where(np.random.random(len(current_position)) < 0.5,\n",
    "                          best_position,\n",
    "                          current_position)\n",
    "    \n",
    "    def fit(self, X, y, classifier):\n",
    "        n_total_features = X.shape[1]\n",
    "        population = np.random.randint(2, size=(self.population_size, n_total_features))\n",
    "        for i in range(self.population_size):\n",
    "            if np.sum(population[i]) < self.n_features:\n",
    "                random_indices = np.random.choice(\n",
    "                    n_total_features, \n",
    "                    self.n_features - np.sum(population[i]),\n",
    "                    replace=False\n",
    "                )\n",
    "                population[i, random_indices] = 1\n",
    "        \n",
    "        global_best_position = None\n",
    "        global_best_fitness = float('-inf')\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            fitness_values = np.array([\n",
    "                self.fitness_function(position, X, y, classifier)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            current_best_idx = np.argmax(fitness_values)\n",
    "            if fitness_values[current_best_idx] > global_best_fitness:\n",
    "                global_best_fitness = fitness_values[current_best_idx]\n",
    "                global_best_position = population[current_best_idx].copy()\n",
    "            \n",
    "            new_population = np.array([\n",
    "                self.honey_badger_movement(position, global_best_position)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            population = new_population\n",
    "        \n",
    "        self.best_features = global_best_position\n",
    "        self.best_fitness = global_best_fitness\n",
    "        return self\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    # Read training and testing data\n",
    "    train_data = pd.read_csv('Training Data/MW1_FS_TrainData.csv')\n",
    "    test_data = pd.read_csv('Testing Data/MW1_FS_TestData.csv')\n",
    "    \n",
    "    # Separate features and target for both datasets\n",
    "    X_train = train_data.drop('Defective', axis=1)\n",
    "    y_train = train_data['Defective']\n",
    "    X_test = test_data.drop('Defective', axis=1)\n",
    "    y_test = test_data['Defective']\n",
    "    \n",
    "    # Convert target to numeric\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test, n_features=5):\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Initialize SVM\n",
    "    svm = SVC(kernel='rbf', random_state=42, probability=True)\n",
    "    \n",
    "    # Feature selection using training data\n",
    "    print(\"Starting feature selection...\")\n",
    "    hb = HoneyBadgerFeatureSelection(n_features_to_select=n_features)\n",
    "    hb.fit(X_train_scaled, y_train, svm)\n",
    "    \n",
    "    # Get selected features\n",
    "    selected_features = np.where(hb.best_features == 1)[0]\n",
    "    selected_feature_names = X_train.columns[selected_features].tolist()\n",
    "    \n",
    "    # Train final model with selected features\n",
    "    X_train_selected = X_train_scaled[:, selected_features]\n",
    "    X_test_selected = X_test_scaled[:, selected_features]\n",
    "    \n",
    "    final_svm = SVC(kernel='rbf', random_state=42, probability=True)\n",
    "    final_svm.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    y_pred = final_svm.predict(X_test_selected)\n",
    "    y_pred_proba = final_svm.predict_proba(X_test_selected)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f_measure = f1_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'model': final_svm,\n",
    "        'selected_features': selected_feature_names,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f_measure': f_measure,\n",
    "        'auc_score': auc_score,\n",
    "        'confusion_matrix': conf_matrix,\n",
    "        'scaler': scaler,\n",
    "        'selected_indices': selected_features\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    X_train, X_test, y_train, y_test = load_and_preprocess_data()\n",
    "    \n",
    "    # Train model and get results\n",
    "    results = train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test, n_features=5)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nSelected Features:\")\n",
    "    for i, feature in enumerate(results['selected_features'], 1):\n",
    "        print(f\"{i}. {feature}\")\n",
    "    \n",
    "    print(f\"\\nModel Performance Metrics:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {results['precision']:.4f}\")\n",
    "    print(f\"Recall: {results['recall']:.4f}\")\n",
    "    print(f\"F-measure: {results['f_measure']:.4f}\")\n",
    "    print(f\"AUC Score: {results['auc_score']:.4f}\")\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"[True Negatives  False Positives]\")\n",
    "    print(\"[False Negatives True Positives]\")\n",
    "    print(results['confusion_matrix'])\n",
    "    \n",
    "    # Additional analysis of selected features\n",
    "    print(\"\\nFeature Importance Analysis:\")\n",
    "    for feature, idx in zip(results['selected_features'], results['selected_indices']):\n",
    "        print(f\"{feature}: Original index {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48db6f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature selection...\n",
      "\n",
      "Selected Features:\n",
      "1. LOC_CODE_AND_COMMENT\n",
      "2. NUMBER_OF_LINES\n",
      "3. LOC_TOTAL\n",
      "\n",
      "Model Performance Metrics:\n",
      "Accuracy: 0.9314\n",
      "Precision: 1.0000\n",
      "Recall: 0.1765\n",
      "F-measure: 0.3000\n",
      "AUC Score: 0.7408\n",
      "\n",
      "Confusion Matrix:\n",
      "[True Negatives  False Positives]\n",
      "[False Negatives True Positives]\n",
      "[[187   0]\n",
      " [ 14   3]]\n",
      "\n",
      "Feature Importance Analysis:\n",
      "LOC_CODE_AND_COMMENT: Original index 1\n",
      "NUMBER_OF_LINES: Original index 5\n",
      "LOC_TOTAL: Original index 6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class HoneyBadgerFeatureSelection:\n",
    "    def __init__(self, n_features_to_select=5, max_iter=50, population_size=20):\n",
    "        self.n_features = n_features_to_select\n",
    "        self.max_iter = max_iter\n",
    "        self.population_size = population_size\n",
    "        self.best_features = None\n",
    "        self.best_fitness = float('-inf')\n",
    "    \n",
    "    def fitness_function(self, selected_features, X, y, classifier):\n",
    "        if np.sum(selected_features) == 0:\n",
    "            return float('-inf')\n",
    "            \n",
    "        X_selected = X[:, selected_features == 1]\n",
    "        try:\n",
    "            classifier.fit(X_selected, y)\n",
    "            y_pred = classifier.predict(X_selected)\n",
    "            return accuracy_score(y, y_pred)\n",
    "        except:\n",
    "            return float('-inf')\n",
    "    \n",
    "    def honey_badger_movement(self, current_position, best_position):\n",
    "        r = np.random.random()\n",
    "        if r < 0.5:\n",
    "            return np.where(np.random.random(len(current_position)) < 0.3,\n",
    "                          1 - current_position,\n",
    "                          current_position)\n",
    "        else:\n",
    "            return np.where(np.random.random(len(current_position)) < 0.5,\n",
    "                          best_position,\n",
    "                          current_position)\n",
    "    \n",
    "    def fit(self, X, y, classifier):\n",
    "        n_total_features = X.shape[1]\n",
    "        population = np.random.randint(2, size=(self.population_size, n_total_features))\n",
    "        for i in range(self.population_size):\n",
    "            if np.sum(population[i]) < self.n_features:\n",
    "                random_indices = np.random.choice(\n",
    "                    n_total_features, \n",
    "                    self.n_features - np.sum(population[i]),\n",
    "                    replace=False\n",
    "                )\n",
    "                population[i, random_indices] = 1\n",
    "        \n",
    "        global_best_position = None\n",
    "        global_best_fitness = float('-inf')\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            fitness_values = np.array([\n",
    "                self.fitness_function(position, X, y, classifier)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            current_best_idx = np.argmax(fitness_values)\n",
    "            if fitness_values[current_best_idx] > global_best_fitness:\n",
    "                global_best_fitness = fitness_values[current_best_idx]\n",
    "                global_best_position = population[current_best_idx].copy()\n",
    "            \n",
    "            new_population = np.array([\n",
    "                self.honey_badger_movement(position, global_best_position)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            population = new_population\n",
    "        \n",
    "        self.best_features = global_best_position\n",
    "        self.best_fitness = global_best_fitness\n",
    "        return self\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    # Read training and testing data\n",
    "    train_data = pd.read_csv('Training Data/PC1_FS_TrainData.csv')\n",
    "    test_data = pd.read_csv('Testing Data/PC1_FS_TestData.csv')\n",
    "    \n",
    "    # Separate features and target for both datasets\n",
    "    X_train = train_data.drop('Defective', axis=1)\n",
    "    y_train = train_data['Defective']\n",
    "    X_test = test_data.drop('Defective', axis=1)\n",
    "    y_test = test_data['Defective']\n",
    "    \n",
    "    # Convert target to numeric\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test, n_features=5):\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Initialize SVM\n",
    "    svm = SVC(kernel='rbf', random_state=42, probability=True)\n",
    "    \n",
    "    # Feature selection using training data\n",
    "    print(\"Starting feature selection...\")\n",
    "    hb = HoneyBadgerFeatureSelection(n_features_to_select=n_features)\n",
    "    hb.fit(X_train_scaled, y_train, svm)\n",
    "    \n",
    "    # Get selected features\n",
    "    selected_features = np.where(hb.best_features == 1)[0]\n",
    "    selected_feature_names = X_train.columns[selected_features].tolist()\n",
    "    \n",
    "    # Train final model with selected features\n",
    "    X_train_selected = X_train_scaled[:, selected_features]\n",
    "    X_test_selected = X_test_scaled[:, selected_features]\n",
    "    \n",
    "    final_svm = SVC(kernel='rbf', random_state=42, probability=True)\n",
    "    final_svm.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    y_pred = final_svm.predict(X_test_selected)\n",
    "    y_pred_proba = final_svm.predict_proba(X_test_selected)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f_measure = f1_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'model': final_svm,\n",
    "        'selected_features': selected_feature_names,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f_measure': f_measure,\n",
    "        'auc_score': auc_score,\n",
    "        'confusion_matrix': conf_matrix,\n",
    "        'scaler': scaler,\n",
    "        'selected_indices': selected_features\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    X_train, X_test, y_train, y_test = load_and_preprocess_data()\n",
    "    \n",
    "    # Train model and get results\n",
    "    results = train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test, n_features=5)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nSelected Features:\")\n",
    "    for i, feature in enumerate(results['selected_features'], 1):\n",
    "        print(f\"{i}. {feature}\")\n",
    "    \n",
    "    print(f\"\\nModel Performance Metrics:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {results['precision']:.4f}\")\n",
    "    print(f\"Recall: {results['recall']:.4f}\")\n",
    "    print(f\"F-measure: {results['f_measure']:.4f}\")\n",
    "    print(f\"AUC Score: {results['auc_score']:.4f}\")\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"[True Negatives  False Positives]\")\n",
    "    print(\"[False Negatives True Positives]\")\n",
    "    print(results['confusion_matrix'])\n",
    "    \n",
    "    # Additional analysis of selected features\n",
    "    print(\"\\nFeature Importance Analysis:\")\n",
    "    for feature, idx in zip(results['selected_features'], results['selected_indices']):\n",
    "        print(f\"{feature}: Original index {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "241daa95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature selection...\n",
      "\n",
      "Selected Features:\n",
      "1. LOC_BLANK\n",
      "2. LOC_CODE_AND_COMMENT\n",
      "3. HALSTEAD_CONTENT\n",
      "4. NORMALIZED_CYLOMATIC_COMPLEXITY\n",
      "5. NUM_UNIQUE_OPERATORS\n",
      "6. NUMBER_OF_LINES\n",
      "\n",
      "Model Performance Metrics:\n",
      "Accuracy: 0.8766\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F-measure: 0.0000\n",
      "AUC Score: 0.7561\n",
      "\n",
      "Confusion Matrix:\n",
      "[True Negatives  False Positives]\n",
      "[False Negatives True Positives]\n",
      "[[277   0]\n",
      " [ 39   0]]\n",
      "\n",
      "Feature Importance Analysis:\n",
      "LOC_BLANK: Original index 0\n",
      "LOC_CODE_AND_COMMENT: Original index 1\n",
      "HALSTEAD_CONTENT: Original index 2\n",
      "NORMALIZED_CYLOMATIC_COMPLEXITY: Original index 3\n",
      "NUM_UNIQUE_OPERATORS: Original index 6\n",
      "NUMBER_OF_LINES: Original index 7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class HoneyBadgerFeatureSelection:\n",
    "    def __init__(self, n_features_to_select=5, max_iter=50, population_size=20):\n",
    "        self.n_features = n_features_to_select\n",
    "        self.max_iter = max_iter\n",
    "        self.population_size = population_size\n",
    "        self.best_features = None\n",
    "        self.best_fitness = float('-inf')\n",
    "    \n",
    "    def fitness_function(self, selected_features, X, y, classifier):\n",
    "        if np.sum(selected_features) == 0:\n",
    "            return float('-inf')\n",
    "            \n",
    "        X_selected = X[:, selected_features == 1]\n",
    "        try:\n",
    "            classifier.fit(X_selected, y)\n",
    "            y_pred = classifier.predict(X_selected)\n",
    "            return accuracy_score(y, y_pred)\n",
    "        except:\n",
    "            return float('-inf')\n",
    "    \n",
    "    def honey_badger_movement(self, current_position, best_position):\n",
    "        r = np.random.random()\n",
    "        if r < 0.5:\n",
    "            return np.where(np.random.random(len(current_position)) < 0.3,\n",
    "                          1 - current_position,\n",
    "                          current_position)\n",
    "        else:\n",
    "            return np.where(np.random.random(len(current_position)) < 0.5,\n",
    "                          best_position,\n",
    "                          current_position)\n",
    "    \n",
    "    def fit(self, X, y, classifier):\n",
    "        n_total_features = X.shape[1]\n",
    "        population = np.random.randint(2, size=(self.population_size, n_total_features))\n",
    "        for i in range(self.population_size):\n",
    "            if np.sum(population[i]) < self.n_features:\n",
    "                random_indices = np.random.choice(\n",
    "                    n_total_features, \n",
    "                    self.n_features - np.sum(population[i]),\n",
    "                    replace=False\n",
    "                )\n",
    "                population[i, random_indices] = 1\n",
    "        \n",
    "        global_best_position = None\n",
    "        global_best_fitness = float('-inf')\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            fitness_values = np.array([\n",
    "                self.fitness_function(position, X, y, classifier)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            current_best_idx = np.argmax(fitness_values)\n",
    "            if fitness_values[current_best_idx] > global_best_fitness:\n",
    "                global_best_fitness = fitness_values[current_best_idx]\n",
    "                global_best_position = population[current_best_idx].copy()\n",
    "            \n",
    "            new_population = np.array([\n",
    "                self.honey_badger_movement(position, global_best_position)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            population = new_population\n",
    "        \n",
    "        self.best_features = global_best_position\n",
    "        self.best_fitness = global_best_fitness\n",
    "        return self\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    # Read training and testing data\n",
    "    train_data = pd.read_csv('Training Data/PC3_FS_TrainData.csv')\n",
    "    test_data = pd.read_csv('Testing Data/PC3_FS_TestData.csv')\n",
    "    \n",
    "    # Separate features and target for both datasets\n",
    "    X_train = train_data.drop('Defective', axis=1)\n",
    "    y_train = train_data['Defective']\n",
    "    X_test = test_data.drop('Defective', axis=1)\n",
    "    y_test = test_data['Defective']\n",
    "    \n",
    "    # Convert target to numeric\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test, n_features=5):\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Initialize SVM\n",
    "    svm = SVC(kernel='rbf', random_state=42, probability=True)\n",
    "    \n",
    "    # Feature selection using training data\n",
    "    print(\"Starting feature selection...\")\n",
    "    hb = HoneyBadgerFeatureSelection(n_features_to_select=n_features)\n",
    "    hb.fit(X_train_scaled, y_train, svm)\n",
    "    \n",
    "    # Get selected features\n",
    "    selected_features = np.where(hb.best_features == 1)[0]\n",
    "    selected_feature_names = X_train.columns[selected_features].tolist()\n",
    "    \n",
    "    # Train final model with selected features\n",
    "    X_train_selected = X_train_scaled[:, selected_features]\n",
    "    X_test_selected = X_test_scaled[:, selected_features]\n",
    "    \n",
    "    final_svm = SVC(kernel='rbf', random_state=42, probability=True)\n",
    "    final_svm.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    y_pred = final_svm.predict(X_test_selected)\n",
    "    y_pred_proba = final_svm.predict_proba(X_test_selected)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f_measure = f1_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'model': final_svm,\n",
    "        'selected_features': selected_feature_names,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f_measure': f_measure,\n",
    "        'auc_score': auc_score,\n",
    "        'confusion_matrix': conf_matrix,\n",
    "        'scaler': scaler,\n",
    "        'selected_indices': selected_features\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    X_train, X_test, y_train, y_test = load_and_preprocess_data()\n",
    "    \n",
    "    # Train model and get results\n",
    "    results = train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test, n_features=5)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nSelected Features:\")\n",
    "    for i, feature in enumerate(results['selected_features'], 1):\n",
    "        print(f\"{i}. {feature}\")\n",
    "    \n",
    "    print(f\"\\nModel Performance Metrics:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {results['precision']:.4f}\")\n",
    "    print(f\"Recall: {results['recall']:.4f}\")\n",
    "    print(f\"F-measure: {results['f_measure']:.4f}\")\n",
    "    print(f\"AUC Score: {results['auc_score']:.4f}\")\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"[True Negatives  False Positives]\")\n",
    "    print(\"[False Negatives True Positives]\")\n",
    "    print(results['confusion_matrix'])\n",
    "    \n",
    "    # Additional analysis of selected features\n",
    "    print(\"\\nFeature Importance Analysis:\")\n",
    "    for feature, idx in zip(results['selected_features'], results['selected_indices']):\n",
    "        print(f\"{feature}: Original index {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6413767b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature selection...\n",
      "\n",
      "Selected Features:\n",
      "1. LOC_BLANK\n",
      "2. LOC_CODE_AND_COMMENT\n",
      "3. HALSTEAD_LENGTH\n",
      "4. MODIFIED_CONDITION_COUNT\n",
      "\n",
      "Model Performance Metrics:\n",
      "Accuracy: 0.8845\n",
      "Precision: 0.8462\n",
      "Recall: 0.2075\n",
      "F-measure: 0.3333\n",
      "AUC Score: 0.6689\n",
      "\n",
      "Confusion Matrix:\n",
      "[True Negatives  False Positives]\n",
      "[False Negatives True Positives]\n",
      "[[326   2]\n",
      " [ 42  11]]\n",
      "\n",
      "Feature Importance Analysis:\n",
      "LOC_BLANK: Original index 0\n",
      "LOC_CODE_AND_COMMENT: Original index 1\n",
      "HALSTEAD_LENGTH: Original index 4\n",
      "MODIFIED_CONDITION_COUNT: Original index 5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class HoneyBadgerFeatureSelection:\n",
    "    def __init__(self, n_features_to_select=5, max_iter=50, population_size=20):\n",
    "        self.n_features = n_features_to_select\n",
    "        self.max_iter = max_iter\n",
    "        self.population_size = population_size\n",
    "        self.best_features = None\n",
    "        self.best_fitness = float('-inf')\n",
    "    \n",
    "    def fitness_function(self, selected_features, X, y, classifier):\n",
    "        if np.sum(selected_features) == 0:\n",
    "            return float('-inf')\n",
    "            \n",
    "        X_selected = X[:, selected_features == 1]\n",
    "        try:\n",
    "            classifier.fit(X_selected, y)\n",
    "            y_pred = classifier.predict(X_selected)\n",
    "            return accuracy_score(y, y_pred)\n",
    "        except:\n",
    "            return float('-inf')\n",
    "    \n",
    "    def honey_badger_movement(self, current_position, best_position):\n",
    "        r = np.random.random()\n",
    "        if r < 0.5:\n",
    "            return np.where(np.random.random(len(current_position)) < 0.3,\n",
    "                          1 - current_position,\n",
    "                          current_position)\n",
    "        else:\n",
    "            return np.where(np.random.random(len(current_position)) < 0.5,\n",
    "                          best_position,\n",
    "                          current_position)\n",
    "    \n",
    "    def fit(self, X, y, classifier):\n",
    "        n_total_features = X.shape[1]\n",
    "        population = np.random.randint(2, size=(self.population_size, n_total_features))\n",
    "        for i in range(self.population_size):\n",
    "            if np.sum(population[i]) < self.n_features:\n",
    "                random_indices = np.random.choice(\n",
    "                    n_total_features, \n",
    "                    self.n_features - np.sum(population[i]),\n",
    "                    replace=False\n",
    "                )\n",
    "                population[i, random_indices] = 1\n",
    "        \n",
    "        global_best_position = None\n",
    "        global_best_fitness = float('-inf')\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            fitness_values = np.array([\n",
    "                self.fitness_function(position, X, y, classifier)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            current_best_idx = np.argmax(fitness_values)\n",
    "            if fitness_values[current_best_idx] > global_best_fitness:\n",
    "                global_best_fitness = fitness_values[current_best_idx]\n",
    "                global_best_position = population[current_best_idx].copy()\n",
    "            \n",
    "            new_population = np.array([\n",
    "                self.honey_badger_movement(position, global_best_position)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            population = new_population\n",
    "        \n",
    "        self.best_features = global_best_position\n",
    "        self.best_fitness = global_best_fitness\n",
    "        return self\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    # Read training and testing data\n",
    "    train_data = pd.read_csv('Training Data/PC4_FS_TrainData.csv')\n",
    "    test_data = pd.read_csv('Testing Data/PC4_FS_TestData.csv')\n",
    "    \n",
    "    # Separate features and target for both datasets\n",
    "    X_train = train_data.drop('Defective', axis=1)\n",
    "    y_train = train_data['Defective']\n",
    "    X_test = test_data.drop('Defective', axis=1)\n",
    "    y_test = test_data['Defective']\n",
    "    \n",
    "    # Convert target to numeric\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test, n_features=5):\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Initialize SVM\n",
    "    svm = SVC(kernel='rbf', random_state=42, probability=True)\n",
    "    \n",
    "    # Feature selection using training data\n",
    "    print(\"Starting feature selection...\")\n",
    "    hb = HoneyBadgerFeatureSelection(n_features_to_select=n_features)\n",
    "    hb.fit(X_train_scaled, y_train, svm)\n",
    "    \n",
    "    # Get selected features\n",
    "    selected_features = np.where(hb.best_features == 1)[0]\n",
    "    selected_feature_names = X_train.columns[selected_features].tolist()\n",
    "    \n",
    "    # Train final model with selected features\n",
    "    X_train_selected = X_train_scaled[:, selected_features]\n",
    "    X_test_selected = X_test_scaled[:, selected_features]\n",
    "    \n",
    "    final_svm = SVC(kernel='rbf', random_state=42, probability=True)\n",
    "    final_svm.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    y_pred = final_svm.predict(X_test_selected)\n",
    "    y_pred_proba = final_svm.predict_proba(X_test_selected)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f_measure = f1_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'model': final_svm,\n",
    "        'selected_features': selected_feature_names,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f_measure': f_measure,\n",
    "        'auc_score': auc_score,\n",
    "        'confusion_matrix': conf_matrix,\n",
    "        'scaler': scaler,\n",
    "        'selected_indices': selected_features\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    X_train, X_test, y_train, y_test = load_and_preprocess_data()\n",
    "    \n",
    "    # Train model and get results\n",
    "    results = train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test, n_features=5)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nSelected Features:\")\n",
    "    for i, feature in enumerate(results['selected_features'], 1):\n",
    "        print(f\"{i}. {feature}\")\n",
    "    \n",
    "    print(f\"\\nModel Performance Metrics:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {results['precision']:.4f}\")\n",
    "    print(f\"Recall: {results['recall']:.4f}\")\n",
    "    print(f\"F-measure: {results['f_measure']:.4f}\")\n",
    "    print(f\"AUC Score: {results['auc_score']:.4f}\")\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"[True Negatives  False Positives]\")\n",
    "    print(\"[False Negatives True Positives]\")\n",
    "    print(results['confusion_matrix'])\n",
    "    \n",
    "    # Additional analysis of selected features\n",
    "    print(\"\\nFeature Importance Analysis:\")\n",
    "    for feature, idx in zip(results['selected_features'], results['selected_indices']):\n",
    "        print(f\"{feature}: Original index {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5b195e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e3e108",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
