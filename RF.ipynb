{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b061523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature selection at: 1737296827.1214557\n",
      "\n",
      "Selected Features:\n",
      "1. LOC_COMMENTS (Importance: 0.2507)\n",
      "2. HALSTEAD_CONTENT (Importance: 0.3138)\n",
      "3. HALSTEAD_ERROR_EST (Importance: 0.2191)\n",
      "4. NUMBER_OF_LINES (Importance: 0.2164)\n",
      "\n",
      "Model Performance Metrics:\n",
      "Accuracy: 0.8485\n",
      "Precision: 0.2500\n",
      "Recall: 0.0769\n",
      "F1-measure: 0.1176\n",
      "AUC Score: 0.6377\n",
      "\n",
      "Confusion Matrix:\n",
      "[[83  3]\n",
      " [12  1]]\n",
      "\n",
      "Feature Importance Analysis:\n",
      "LOC_COMMENTS: Original index 1, Importance 0.2507\n",
      "HALSTEAD_CONTENT: Original index 2, Importance 0.3138\n",
      "HALSTEAD_ERROR_EST: Original index 3, Importance 0.2191\n",
      "NUMBER_OF_LINES: Original index 6, Importance 0.2164\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, precision_score, \n",
    "                           recall_score, f1_score, roc_auc_score)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "\n",
    "class HoneyBadgerFeatureSelection:\n",
    "    def __init__(self, n_features_to_select=5, max_iter=50, population_size=20):\n",
    "        self.n_features = n_features_to_select\n",
    "        self.max_iter = max_iter\n",
    "        self.population_size = population_size\n",
    "        self.best_features = None\n",
    "        self.best_fitness = float('-inf')\n",
    "    \n",
    "    def fitness_function(self, selected_features, X, y, classifier):\n",
    "        if np.sum(selected_features) == 0:\n",
    "            return float('-inf')\n",
    "            \n",
    "        X_selected = X[:, selected_features == 1]\n",
    "        try:\n",
    "            classifier.fit(X_selected, y)\n",
    "            y_pred = classifier.predict(X_selected)\n",
    "            return accuracy_score(y, y_pred)\n",
    "        except:\n",
    "            return float('-inf')\n",
    "    \n",
    "    def honey_badger_movement(self, current_position, best_position):\n",
    "        r = np.random.random()\n",
    "        if r < 0.5:\n",
    "            return np.where(np.random.random(len(current_position)) < 0.3,\n",
    "                          1 - current_position,\n",
    "                          current_position)\n",
    "        else:\n",
    "            return np.where(np.random.random(len(current_position)) < 0.5,\n",
    "                          best_position,\n",
    "                          current_position)\n",
    "    \n",
    "    def fit(self, X, y, classifier):\n",
    "        n_total_features = X.shape[1]\n",
    "        population = np.random.randint(2, size=(self.population_size, n_total_features))\n",
    "        for i in range(self.population_size):\n",
    "            if np.sum(population[i]) < self.n_features:\n",
    "                random_indices = np.random.choice(\n",
    "                    n_total_features, \n",
    "                    self.n_features - np.sum(population[i]),\n",
    "                    replace=False\n",
    "                )\n",
    "                population[i, random_indices] = 1\n",
    "        \n",
    "        global_best_position = None\n",
    "        global_best_fitness = float('-inf')\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            fitness_values = np.array([\n",
    "                self.fitness_function(position, X, y, classifier)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            current_best_idx = np.argmax(fitness_values)\n",
    "            if fitness_values[current_best_idx] > global_best_fitness:\n",
    "                global_best_fitness = fitness_values[current_best_idx]\n",
    "                global_best_position = population[current_best_idx].copy()\n",
    "            \n",
    "            new_population = np.array([\n",
    "                self.honey_badger_movement(position, global_best_position)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            population = new_population\n",
    "        \n",
    "        self.best_features = global_best_position\n",
    "        self.best_fitness = global_best_fitness\n",
    "        return self\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    # Read training and testing data\n",
    "    train_data = pd.read_csv('Training Data/CM1_FS_TrainData.csv')\n",
    "    test_data = pd.read_csv('Testing Data/CM1_FS_TestData.csv')\n",
    "    \n",
    "    # Separate features and target for both datasets\n",
    "    X_train = train_data.drop('Defective', axis=1)\n",
    "    y_train = train_data['Defective']\n",
    "    X_test = test_data.drop('Defective', axis=1)\n",
    "    y_test = test_data['Defective']\n",
    "    \n",
    "    # Convert target to numeric\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test, n_features=5):\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Initialize Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Feature selection using training data\n",
    "    print(f\"Starting feature selection at: {time.time()}\")\n",
    "    hb = HoneyBadgerFeatureSelection(n_features_to_select=n_features)\n",
    "    hb.fit(X_train_scaled, y_train, rf)\n",
    "    \n",
    "    # Get selected features\n",
    "    selected_features = np.where(hb.best_features == 1)[0]\n",
    "    selected_feature_names = X_train.columns[selected_features].tolist()\n",
    "    \n",
    "    # Train final model with selected features\n",
    "    X_train_selected = X_train_scaled[:, selected_features]\n",
    "    X_test_selected = X_test_scaled[:, selected_features]\n",
    "    \n",
    "    final_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    final_rf.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = final_rf.predict(X_test_selected)\n",
    "    y_pred_proba = final_rf.predict_proba(X_test_selected)[:, 1]  # For AUC score\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'model': final_rf,\n",
    "        'selected_features': selected_feature_names,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'auc': roc_auc_score(y_test, y_pred_proba),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "        'selected_indices': selected_features,\n",
    "        'feature_importance': final_rf.feature_importances_\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    X_train, X_test, y_train, y_test = load_and_preprocess_data()\n",
    "    \n",
    "    # Train model and get results\n",
    "    results = train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test, n_features=5)\n",
    "    \n",
    "    # Print selected features and their importance\n",
    "    print(\"\\nSelected Features:\")\n",
    "    for i, (feature, importance) in enumerate(zip(results['selected_features'], \n",
    "                                                results['feature_importance']), 1):\n",
    "        print(f\"{i}. {feature} (Importance: {importance:.4f})\")\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"\\nModel Performance Metrics:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {results['precision']:.4f}\")\n",
    "    print(f\"Recall: {results['recall']:.4f}\")\n",
    "    print(f\"F1-measure: {results['f1']:.4f}\")\n",
    "    print(f\"AUC Score: {results['auc']:.4f}\")\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(results['confusion_matrix'])\n",
    "    \n",
    "    # Feature importance analysis\n",
    "    print(\"\\nFeature Importance Analysis:\")\n",
    "    for feature, idx, importance in zip(results['selected_features'], \n",
    "                                      results['selected_indices'],\n",
    "                                      results['feature_importance']):\n",
    "        print(f\"{feature}: Original index {idx}, Importance {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21a6fb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature selection at: 1737297090.29487\n",
      "\n",
      "Selected Features:\n",
      "1. LOC_BLANK (Importance: 0.1988)\n",
      "2. LOC_COMMENTS (Importance: 0.1786)\n",
      "3. DESIGN_COMPLEXITY (Importance: 0.1805)\n",
      "4. GLOBAL_DATA_COMPLEXITY (Importance: 0.1960)\n",
      "5. LOC_TOTAL (Importance: 0.2462)\n",
      "\n",
      "Model Performance Metrics:\n",
      "Accuracy: 0.6053\n",
      "Precision: 0.3333\n",
      "Recall: 0.1538\n",
      "F1-measure: 0.2105\n",
      "AUC Score: 0.5277\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21  4]\n",
      " [11  2]]\n",
      "\n",
      "Feature Importance Analysis:\n",
      "LOC_BLANK: Original index 0, Importance 0.1988\n",
      "LOC_COMMENTS: Original index 1, Importance 0.1786\n",
      "DESIGN_COMPLEXITY: Original index 2, Importance 0.1805\n",
      "GLOBAL_DATA_COMPLEXITY: Original index 5, Importance 0.1960\n",
      "LOC_TOTAL: Original index 9, Importance 0.2462\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, precision_score, \n",
    "                           recall_score, f1_score, roc_auc_score)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "\n",
    "class HoneyBadgerFeatureSelection:\n",
    "    def __init__(self, n_features_to_select=5, max_iter=50, population_size=20):\n",
    "        self.n_features = n_features_to_select\n",
    "        self.max_iter = max_iter\n",
    "        self.population_size = population_size\n",
    "        self.best_features = None\n",
    "        self.best_fitness = float('-inf')\n",
    "    \n",
    "    def fitness_function(self, selected_features, X, y, classifier):\n",
    "        if np.sum(selected_features) == 0:\n",
    "            return float('-inf')\n",
    "            \n",
    "        X_selected = X[:, selected_features == 1]\n",
    "        try:\n",
    "            classifier.fit(X_selected, y)\n",
    "            y_pred = classifier.predict(X_selected)\n",
    "            return accuracy_score(y, y_pred)\n",
    "        except:\n",
    "            return float('-inf')\n",
    "    \n",
    "    def honey_badger_movement(self, current_position, best_position):\n",
    "        r = np.random.random()\n",
    "        if r < 0.5:\n",
    "            return np.where(np.random.random(len(current_position)) < 0.3,\n",
    "                          1 - current_position,\n",
    "                          current_position)\n",
    "        else:\n",
    "            return np.where(np.random.random(len(current_position)) < 0.5,\n",
    "                          best_position,\n",
    "                          current_position)\n",
    "    \n",
    "    def fit(self, X, y, classifier):\n",
    "        n_total_features = X.shape[1]\n",
    "        population = np.random.randint(2, size=(self.population_size, n_total_features))\n",
    "        for i in range(self.population_size):\n",
    "            if np.sum(population[i]) < self.n_features:\n",
    "                random_indices = np.random.choice(\n",
    "                    n_total_features, \n",
    "                    self.n_features - np.sum(population[i]),\n",
    "                    replace=False\n",
    "                )\n",
    "                population[i, random_indices] = 1\n",
    "        \n",
    "        global_best_position = None\n",
    "        global_best_fitness = float('-inf')\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            fitness_values = np.array([\n",
    "                self.fitness_function(position, X, y, classifier)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            current_best_idx = np.argmax(fitness_values)\n",
    "            if fitness_values[current_best_idx] > global_best_fitness:\n",
    "                global_best_fitness = fitness_values[current_best_idx]\n",
    "                global_best_position = population[current_best_idx].copy()\n",
    "            \n",
    "            new_population = np.array([\n",
    "                self.honey_badger_movement(position, global_best_position)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            population = new_population\n",
    "        \n",
    "        self.best_features = global_best_position\n",
    "        self.best_fitness = global_best_fitness\n",
    "        return self\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    # Read training and testing data\n",
    "    train_data = pd.read_csv('Training Data/MC2_FS_TrainData.csv')\n",
    "    test_data = pd.read_csv('Testing Data/MC2_FS_TestData.csv')\n",
    "    \n",
    "    # Separate features and target for both datasets\n",
    "    X_train = train_data.drop('Defective', axis=1)\n",
    "    y_train = train_data['Defective']\n",
    "    X_test = test_data.drop('Defective', axis=1)\n",
    "    y_test = test_data['Defective']\n",
    "    \n",
    "    # Convert target to numeric\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test, n_features=5):\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Initialize Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Feature selection using training data\n",
    "    print(f\"Starting feature selection at: {time.time()}\")\n",
    "    hb = HoneyBadgerFeatureSelection(n_features_to_select=n_features)\n",
    "    hb.fit(X_train_scaled, y_train, rf)\n",
    "    \n",
    "    # Get selected features\n",
    "    selected_features = np.where(hb.best_features == 1)[0]\n",
    "    selected_feature_names = X_train.columns[selected_features].tolist()\n",
    "    \n",
    "    # Train final model with selected features\n",
    "    X_train_selected = X_train_scaled[:, selected_features]\n",
    "    X_test_selected = X_test_scaled[:, selected_features]\n",
    "    \n",
    "    final_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    final_rf.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = final_rf.predict(X_test_selected)\n",
    "    y_pred_proba = final_rf.predict_proba(X_test_selected)[:, 1]  # For AUC score\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'model': final_rf,\n",
    "        'selected_features': selected_feature_names,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'auc': roc_auc_score(y_test, y_pred_proba),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "        'selected_indices': selected_features,\n",
    "        'feature_importance': final_rf.feature_importances_\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    X_train, X_test, y_train, y_test = load_and_preprocess_data()\n",
    "    \n",
    "    # Train model and get results\n",
    "    results = train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test, n_features=5)\n",
    "    \n",
    "    # Print selected features and their importance\n",
    "    print(\"\\nSelected Features:\")\n",
    "    for i, (feature, importance) in enumerate(zip(results['selected_features'], \n",
    "                                                results['feature_importance']), 1):\n",
    "        print(f\"{i}. {feature} (Importance: {importance:.4f})\")\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"\\nModel Performance Metrics:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {results['precision']:.4f}\")\n",
    "    print(f\"Recall: {results['recall']:.4f}\")\n",
    "    print(f\"F1-measure: {results['f1']:.4f}\")\n",
    "    print(f\"AUC Score: {results['auc']:.4f}\")\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(results['confusion_matrix'])\n",
    "    \n",
    "    # Feature importance analysis\n",
    "    print(\"\\nFeature Importance Analysis:\")\n",
    "    for feature, idx, importance in zip(results['selected_features'], \n",
    "                                      results['selected_indices'],\n",
    "                                      results['feature_importance']):\n",
    "        print(f\"{feature}: Original index {idx}, Importance {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a778cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature selection at: 1737297331.954764\n",
      "\n",
      "Selected Features:\n",
      "1. DESIGN_COMPLEXITY (Importance: 0.1504)\n",
      "2. HALSTEAD_LENGTH (Importance: 0.2664)\n",
      "3. NUMBER_OF_LINES (Importance: 0.3129)\n",
      "4. LOC_TOTAL (Importance: 0.2702)\n",
      "\n",
      "Model Performance Metrics:\n",
      "Accuracy: 0.8933\n",
      "Precision: 0.5000\n",
      "Recall: 0.1250\n",
      "F1-measure: 0.2000\n",
      "AUC Score: 0.7043\n",
      "\n",
      "Confusion Matrix:\n",
      "[[66  1]\n",
      " [ 7  1]]\n",
      "\n",
      "Feature Importance Analysis:\n",
      "DESIGN_COMPLEXITY: Original index 1, Importance 0.1504\n",
      "HALSTEAD_LENGTH: Original index 4, Importance 0.2664\n",
      "NUMBER_OF_LINES: Original index 6, Importance 0.3129\n",
      "LOC_TOTAL: Original index 7, Importance 0.2702\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, precision_score, \n",
    "                           recall_score, f1_score, roc_auc_score)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "\n",
    "class HoneyBadgerFeatureSelection:\n",
    "    def __init__(self, n_features_to_select=5, max_iter=50, population_size=20):\n",
    "        self.n_features = n_features_to_select\n",
    "        self.max_iter = max_iter\n",
    "        self.population_size = population_size\n",
    "        self.best_features = None\n",
    "        self.best_fitness = float('-inf')\n",
    "    \n",
    "    def fitness_function(self, selected_features, X, y, classifier):\n",
    "        if np.sum(selected_features) == 0:\n",
    "            return float('-inf')\n",
    "            \n",
    "        X_selected = X[:, selected_features == 1]\n",
    "        try:\n",
    "            classifier.fit(X_selected, y)\n",
    "            y_pred = classifier.predict(X_selected)\n",
    "            return accuracy_score(y, y_pred)\n",
    "        except:\n",
    "            return float('-inf')\n",
    "    \n",
    "    def honey_badger_movement(self, current_position, best_position):\n",
    "        r = np.random.random()\n",
    "        if r < 0.5:\n",
    "            return np.where(np.random.random(len(current_position)) < 0.3,\n",
    "                          1 - current_position,\n",
    "                          current_position)\n",
    "        else:\n",
    "            return np.where(np.random.random(len(current_position)) < 0.5,\n",
    "                          best_position,\n",
    "                          current_position)\n",
    "    \n",
    "    def fit(self, X, y, classifier):\n",
    "        n_total_features = X.shape[1]\n",
    "        population = np.random.randint(2, size=(self.population_size, n_total_features))\n",
    "        for i in range(self.population_size):\n",
    "            if np.sum(population[i]) < self.n_features:\n",
    "                random_indices = np.random.choice(\n",
    "                    n_total_features, \n",
    "                    self.n_features - np.sum(population[i]),\n",
    "                    replace=False\n",
    "                )\n",
    "                population[i, random_indices] = 1\n",
    "        \n",
    "        global_best_position = None\n",
    "        global_best_fitness = float('-inf')\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            fitness_values = np.array([\n",
    "                self.fitness_function(position, X, y, classifier)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            current_best_idx = np.argmax(fitness_values)\n",
    "            if fitness_values[current_best_idx] > global_best_fitness:\n",
    "                global_best_fitness = fitness_values[current_best_idx]\n",
    "                global_best_position = population[current_best_idx].copy()\n",
    "            \n",
    "            new_population = np.array([\n",
    "                self.honey_badger_movement(position, global_best_position)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            population = new_population\n",
    "        \n",
    "        self.best_features = global_best_position\n",
    "        self.best_fitness = global_best_fitness\n",
    "        return self\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    # Read training and testing data\n",
    "    train_data = pd.read_csv('Training Data/MW1_FS_TrainData.csv')\n",
    "    test_data = pd.read_csv('Testing Data/MW1_FS_TestData.csv')\n",
    "    \n",
    "    # Separate features and target for both datasets\n",
    "    X_train = train_data.drop('Defective', axis=1)\n",
    "    y_train = train_data['Defective']\n",
    "    X_test = test_data.drop('Defective', axis=1)\n",
    "    y_test = test_data['Defective']\n",
    "    \n",
    "    # Convert target to numeric\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test, n_features=5):\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Initialize Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Feature selection using training data\n",
    "    print(f\"Starting feature selection at: {time.time()}\")\n",
    "    hb = HoneyBadgerFeatureSelection(n_features_to_select=n_features)\n",
    "    hb.fit(X_train_scaled, y_train, rf)\n",
    "    \n",
    "    # Get selected features\n",
    "    selected_features = np.where(hb.best_features == 1)[0]\n",
    "    selected_feature_names = X_train.columns[selected_features].tolist()\n",
    "    \n",
    "    # Train final model with selected features\n",
    "    X_train_selected = X_train_scaled[:, selected_features]\n",
    "    X_test_selected = X_test_scaled[:, selected_features]\n",
    "    \n",
    "    final_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    final_rf.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = final_rf.predict(X_test_selected)\n",
    "    y_pred_proba = final_rf.predict_proba(X_test_selected)[:, 1]  # For AUC score\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'model': final_rf,\n",
    "        'selected_features': selected_feature_names,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'auc': roc_auc_score(y_test, y_pred_proba),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "        'selected_indices': selected_features,\n",
    "        'feature_importance': final_rf.feature_importances_\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    X_train, X_test, y_train, y_test = load_and_preprocess_data()\n",
    "    \n",
    "    # Train model and get results\n",
    "    results = train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test, n_features=5)\n",
    "    \n",
    "    # Print selected features and their importance\n",
    "    print(\"\\nSelected Features:\")\n",
    "    for i, (feature, importance) in enumerate(zip(results['selected_features'], \n",
    "                                                results['feature_importance']), 1):\n",
    "        print(f\"{i}. {feature} (Importance: {importance:.4f})\")\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"\\nModel Performance Metrics:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {results['precision']:.4f}\")\n",
    "    print(f\"Recall: {results['recall']:.4f}\")\n",
    "    print(f\"F1-measure: {results['f1']:.4f}\")\n",
    "    print(f\"AUC Score: {results['auc']:.4f}\")\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(results['confusion_matrix'])\n",
    "    \n",
    "    # Feature importance analysis\n",
    "    print(\"\\nFeature Importance Analysis:\")\n",
    "    for feature, idx, importance in zip(results['selected_features'], \n",
    "                                      results['selected_indices'],\n",
    "                                      results['feature_importance']):\n",
    "        print(f\"{feature}: Original index {idx}, Importance {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "431efac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature selection at: 1737297586.5775292\n",
      "\n",
      "Selected Features:\n",
      "1. LOC_CODE_AND_COMMENT (Importance: 0.1798)\n",
      "2. EDGE_COUNT (Importance: 0.2385)\n",
      "3. HALSTEAD_CONTENT (Importance: 0.2815)\n",
      "4. NUMBER_OF_LINES (Importance: 0.3002)\n",
      "\n",
      "Model Performance Metrics:\n",
      "Accuracy: 0.9216\n",
      "Precision: 0.5714\n",
      "Recall: 0.2353\n",
      "F1-measure: 0.3333\n",
      "AUC Score: 0.8989\n",
      "\n",
      "Confusion Matrix:\n",
      "[[184   3]\n",
      " [ 13   4]]\n",
      "\n",
      "Feature Importance Analysis:\n",
      "LOC_CODE_AND_COMMENT: Original index 1, Importance 0.1798\n",
      "EDGE_COUNT: Original index 2, Importance 0.2385\n",
      "HALSTEAD_CONTENT: Original index 3, Importance 0.2815\n",
      "NUMBER_OF_LINES: Original index 5, Importance 0.3002\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, precision_score, \n",
    "                           recall_score, f1_score, roc_auc_score)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "\n",
    "class HoneyBadgerFeatureSelection:\n",
    "    def __init__(self, n_features_to_select=5, max_iter=50, population_size=20):\n",
    "        self.n_features = n_features_to_select\n",
    "        self.max_iter = max_iter\n",
    "        self.population_size = population_size\n",
    "        self.best_features = None\n",
    "        self.best_fitness = float('-inf')\n",
    "    \n",
    "    def fitness_function(self, selected_features, X, y, classifier):\n",
    "        if np.sum(selected_features) == 0:\n",
    "            return float('-inf')\n",
    "            \n",
    "        X_selected = X[:, selected_features == 1]\n",
    "        try:\n",
    "            classifier.fit(X_selected, y)\n",
    "            y_pred = classifier.predict(X_selected)\n",
    "            return accuracy_score(y, y_pred)\n",
    "        except:\n",
    "            return float('-inf')\n",
    "    \n",
    "    def honey_badger_movement(self, current_position, best_position):\n",
    "        r = np.random.random()\n",
    "        if r < 0.5:\n",
    "            return np.where(np.random.random(len(current_position)) < 0.3,\n",
    "                          1 - current_position,\n",
    "                          current_position)\n",
    "        else:\n",
    "            return np.where(np.random.random(len(current_position)) < 0.5,\n",
    "                          best_position,\n",
    "                          current_position)\n",
    "    \n",
    "    def fit(self, X, y, classifier):\n",
    "        n_total_features = X.shape[1]\n",
    "        population = np.random.randint(2, size=(self.population_size, n_total_features))\n",
    "        for i in range(self.population_size):\n",
    "            if np.sum(population[i]) < self.n_features:\n",
    "                random_indices = np.random.choice(\n",
    "                    n_total_features, \n",
    "                    self.n_features - np.sum(population[i]),\n",
    "                    replace=False\n",
    "                )\n",
    "                population[i, random_indices] = 1\n",
    "        \n",
    "        global_best_position = None\n",
    "        global_best_fitness = float('-inf')\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            fitness_values = np.array([\n",
    "                self.fitness_function(position, X, y, classifier)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            current_best_idx = np.argmax(fitness_values)\n",
    "            if fitness_values[current_best_idx] > global_best_fitness:\n",
    "                global_best_fitness = fitness_values[current_best_idx]\n",
    "                global_best_position = population[current_best_idx].copy()\n",
    "            \n",
    "            new_population = np.array([\n",
    "                self.honey_badger_movement(position, global_best_position)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            population = new_population\n",
    "        \n",
    "        self.best_features = global_best_position\n",
    "        self.best_fitness = global_best_fitness\n",
    "        return self\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    # Read training and testing data\n",
    "    train_data = pd.read_csv('Training Data/PC1_FS_TrainData.csv')\n",
    "    test_data = pd.read_csv('Testing Data/PC1_FS_TestData.csv')\n",
    "    \n",
    "    # Separate features and target for both datasets\n",
    "    X_train = train_data.drop('Defective', axis=1)\n",
    "    y_train = train_data['Defective']\n",
    "    X_test = test_data.drop('Defective', axis=1)\n",
    "    y_test = test_data['Defective']\n",
    "    \n",
    "    # Convert target to numeric\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test, n_features=5):\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Initialize Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Feature selection using training data\n",
    "    print(f\"Starting feature selection at: {time.time()}\")\n",
    "    hb = HoneyBadgerFeatureSelection(n_features_to_select=n_features)\n",
    "    hb.fit(X_train_scaled, y_train, rf)\n",
    "    \n",
    "    # Get selected features\n",
    "    selected_features = np.where(hb.best_features == 1)[0]\n",
    "    selected_feature_names = X_train.columns[selected_features].tolist()\n",
    "    \n",
    "    # Train final model with selected features\n",
    "    X_train_selected = X_train_scaled[:, selected_features]\n",
    "    X_test_selected = X_test_scaled[:, selected_features]\n",
    "    \n",
    "    final_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    final_rf.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = final_rf.predict(X_test_selected)\n",
    "    y_pred_proba = final_rf.predict_proba(X_test_selected)[:, 1]  # For AUC score\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'model': final_rf,\n",
    "        'selected_features': selected_feature_names,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'auc': roc_auc_score(y_test, y_pred_proba),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "        'selected_indices': selected_features,\n",
    "        'feature_importance': final_rf.feature_importances_\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    X_train, X_test, y_train, y_test = load_and_preprocess_data()\n",
    "    \n",
    "    # Train model and get results\n",
    "    results = train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test, n_features=5)\n",
    "    \n",
    "    # Print selected features and their importance\n",
    "    print(\"\\nSelected Features:\")\n",
    "    for i, (feature, importance) in enumerate(zip(results['selected_features'], \n",
    "                                                results['feature_importance']), 1):\n",
    "        print(f\"{i}. {feature} (Importance: {importance:.4f})\")\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"\\nModel Performance Metrics:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {results['precision']:.4f}\")\n",
    "    print(f\"Recall: {results['recall']:.4f}\")\n",
    "    print(f\"F1-measure: {results['f1']:.4f}\")\n",
    "    print(f\"AUC Score: {results['auc']:.4f}\")\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(results['confusion_matrix'])\n",
    "    \n",
    "    # Feature importance analysis\n",
    "    print(\"\\nFeature Importance Analysis:\")\n",
    "    for feature, idx, importance in zip(results['selected_features'], \n",
    "                                      results['selected_indices'],\n",
    "                                      results['feature_importance']):\n",
    "        print(f\"{feature}: Original index {idx}, Importance {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc6952a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature selection at: 1737297874.7572331\n",
      "\n",
      "Selected Features:\n",
      "1. LOC_BLANK (Importance: 0.2189)\n",
      "2. LOC_CODE_AND_COMMENT (Importance: 0.1092)\n",
      "3. HALSTEAD_CONTENT (Importance: 0.2477)\n",
      "4. NUM_OPERANDS (Importance: 0.1908)\n",
      "5. PERCENT_COMMENTS (Importance: 0.2335)\n",
      "\n",
      "Model Performance Metrics:\n",
      "Accuracy: 0.8861\n",
      "Precision: 0.6000\n",
      "Recall: 0.2308\n",
      "F1-measure: 0.3333\n",
      "AUC Score: 0.7814\n",
      "\n",
      "Confusion Matrix:\n",
      "[[271   6]\n",
      " [ 30   9]]\n",
      "\n",
      "Feature Importance Analysis:\n",
      "LOC_BLANK: Original index 0, Importance 0.2189\n",
      "LOC_CODE_AND_COMMENT: Original index 1, Importance 0.1092\n",
      "HALSTEAD_CONTENT: Original index 2, Importance 0.2477\n",
      "NUM_OPERANDS: Original index 4, Importance 0.1908\n",
      "PERCENT_COMMENTS: Original index 8, Importance 0.2335\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, precision_score, \n",
    "                           recall_score, f1_score, roc_auc_score)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "\n",
    "class HoneyBadgerFeatureSelection:\n",
    "    def __init__(self, n_features_to_select=5, max_iter=50, population_size=20):\n",
    "        self.n_features = n_features_to_select\n",
    "        self.max_iter = max_iter\n",
    "        self.population_size = population_size\n",
    "        self.best_features = None\n",
    "        self.best_fitness = float('-inf')\n",
    "    \n",
    "    def fitness_function(self, selected_features, X, y, classifier):\n",
    "        if np.sum(selected_features) == 0:\n",
    "            return float('-inf')\n",
    "            \n",
    "        X_selected = X[:, selected_features == 1]\n",
    "        try:\n",
    "            classifier.fit(X_selected, y)\n",
    "            y_pred = classifier.predict(X_selected)\n",
    "            return accuracy_score(y, y_pred)\n",
    "        except:\n",
    "            return float('-inf')\n",
    "    \n",
    "    def honey_badger_movement(self, current_position, best_position):\n",
    "        r = np.random.random()\n",
    "        if r < 0.5:\n",
    "            return np.where(np.random.random(len(current_position)) < 0.3,\n",
    "                          1 - current_position,\n",
    "                          current_position)\n",
    "        else:\n",
    "            return np.where(np.random.random(len(current_position)) < 0.5,\n",
    "                          best_position,\n",
    "                          current_position)\n",
    "    \n",
    "    def fit(self, X, y, classifier):\n",
    "        n_total_features = X.shape[1]\n",
    "        population = np.random.randint(2, size=(self.population_size, n_total_features))\n",
    "        for i in range(self.population_size):\n",
    "            if np.sum(population[i]) < self.n_features:\n",
    "                random_indices = np.random.choice(\n",
    "                    n_total_features, \n",
    "                    self.n_features - np.sum(population[i]),\n",
    "                    replace=False\n",
    "                )\n",
    "                population[i, random_indices] = 1\n",
    "        \n",
    "        global_best_position = None\n",
    "        global_best_fitness = float('-inf')\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            fitness_values = np.array([\n",
    "                self.fitness_function(position, X, y, classifier)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            current_best_idx = np.argmax(fitness_values)\n",
    "            if fitness_values[current_best_idx] > global_best_fitness:\n",
    "                global_best_fitness = fitness_values[current_best_idx]\n",
    "                global_best_position = population[current_best_idx].copy()\n",
    "            \n",
    "            new_population = np.array([\n",
    "                self.honey_badger_movement(position, global_best_position)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            population = new_population\n",
    "        \n",
    "        self.best_features = global_best_position\n",
    "        self.best_fitness = global_best_fitness\n",
    "        return self\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    # Read training and testing data\n",
    "    train_data = pd.read_csv('Training Data/PC3_FS_TrainData.csv')\n",
    "    test_data = pd.read_csv('Testing Data/PC3_FS_TestData.csv')\n",
    "    \n",
    "    # Separate features and target for both datasets\n",
    "    X_train = train_data.drop('Defective', axis=1)\n",
    "    y_train = train_data['Defective']\n",
    "    X_test = test_data.drop('Defective', axis=1)\n",
    "    y_test = test_data['Defective']\n",
    "    \n",
    "    # Convert target to numeric\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test, n_features=5):\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Initialize Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Feature selection using training data\n",
    "    print(f\"Starting feature selection at: {time.time()}\")\n",
    "    hb = HoneyBadgerFeatureSelection(n_features_to_select=n_features)\n",
    "    hb.fit(X_train_scaled, y_train, rf)\n",
    "    \n",
    "    # Get selected features\n",
    "    selected_features = np.where(hb.best_features == 1)[0]\n",
    "    selected_feature_names = X_train.columns[selected_features].tolist()\n",
    "    \n",
    "    # Train final model with selected features\n",
    "    X_train_selected = X_train_scaled[:, selected_features]\n",
    "    X_test_selected = X_test_scaled[:, selected_features]\n",
    "    \n",
    "    final_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    final_rf.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = final_rf.predict(X_test_selected)\n",
    "    y_pred_proba = final_rf.predict_proba(X_test_selected)[:, 1]  # For AUC score\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'model': final_rf,\n",
    "        'selected_features': selected_feature_names,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'auc': roc_auc_score(y_test, y_pred_proba),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "        'selected_indices': selected_features,\n",
    "        'feature_importance': final_rf.feature_importances_\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    X_train, X_test, y_train, y_test = load_and_preprocess_data()\n",
    "    \n",
    "    # Train model and get results\n",
    "    results = train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test, n_features=5)\n",
    "    \n",
    "    # Print selected features and their importance\n",
    "    print(\"\\nSelected Features:\")\n",
    "    for i, (feature, importance) in enumerate(zip(results['selected_features'], \n",
    "                                                results['feature_importance']), 1):\n",
    "        print(f\"{i}. {feature} (Importance: {importance:.4f})\")\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"\\nModel Performance Metrics:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {results['precision']:.4f}\")\n",
    "    print(f\"Recall: {results['recall']:.4f}\")\n",
    "    print(f\"F1-measure: {results['f1']:.4f}\")\n",
    "    print(f\"AUC Score: {results['auc']:.4f}\")\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(results['confusion_matrix'])\n",
    "    \n",
    "    # Feature importance analysis\n",
    "    print(\"\\nFeature Importance Analysis:\")\n",
    "    for feature, idx, importance in zip(results['selected_features'], \n",
    "                                      results['selected_indices'],\n",
    "                                      results['feature_importance']):\n",
    "        print(f\"{feature}: Original index {idx}, Importance {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2150c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature selection at: 1737298210.4255514\n",
      "\n",
      "Selected Features:\n",
      "1. LOC_CODE_AND_COMMENT (Importance: 0.2584)\n",
      "2. ESSENTIAL_COMPLEXITY (Importance: 0.0462)\n",
      "3. HALSTEAD_LENGTH (Importance: 0.1781)\n",
      "4. MODIFIED_CONDITION_COUNT (Importance: 0.0784)\n",
      "5. MULTIPLE_CONDITION_COUNT (Importance: 0.0940)\n",
      "6. NORMALIZED_CYLOMATIC_COMPLEXITY (Importance: 0.1306)\n",
      "7. PERCENT_COMMENTS (Importance: 0.2142)\n",
      "\n",
      "Model Performance Metrics:\n",
      "Accuracy: 0.8819\n",
      "Precision: 0.6053\n",
      "Recall: 0.4340\n",
      "F1-measure: 0.5055\n",
      "AUC Score: 0.9015\n",
      "\n",
      "Confusion Matrix:\n",
      "[[313  15]\n",
      " [ 30  23]]\n",
      "\n",
      "Feature Importance Analysis:\n",
      "LOC_CODE_AND_COMMENT: Original index 1, Importance 0.2584\n",
      "ESSENTIAL_COMPLEXITY: Original index 3, Importance 0.0462\n",
      "HALSTEAD_LENGTH: Original index 4, Importance 0.1781\n",
      "MODIFIED_CONDITION_COUNT: Original index 5, Importance 0.0784\n",
      "MULTIPLE_CONDITION_COUNT: Original index 6, Importance 0.0940\n",
      "NORMALIZED_CYLOMATIC_COMPLEXITY: Original index 7, Importance 0.1306\n",
      "PERCENT_COMMENTS: Original index 8, Importance 0.2142\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, precision_score, \n",
    "                           recall_score, f1_score, roc_auc_score)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "\n",
    "class HoneyBadgerFeatureSelection:\n",
    "    def __init__(self, n_features_to_select=5, max_iter=50, population_size=20):\n",
    "        self.n_features = n_features_to_select\n",
    "        self.max_iter = max_iter\n",
    "        self.population_size = population_size\n",
    "        self.best_features = None\n",
    "        self.best_fitness = float('-inf')\n",
    "    \n",
    "    def fitness_function(self, selected_features, X, y, classifier):\n",
    "        if np.sum(selected_features) == 0:\n",
    "            return float('-inf')\n",
    "            \n",
    "        X_selected = X[:, selected_features == 1]\n",
    "        try:\n",
    "            classifier.fit(X_selected, y)\n",
    "            y_pred = classifier.predict(X_selected)\n",
    "            return accuracy_score(y, y_pred)\n",
    "        except:\n",
    "            return float('-inf')\n",
    "    \n",
    "    def honey_badger_movement(self, current_position, best_position):\n",
    "        r = np.random.random()\n",
    "        if r < 0.5:\n",
    "            return np.where(np.random.random(len(current_position)) < 0.3,\n",
    "                          1 - current_position,\n",
    "                          current_position)\n",
    "        else:\n",
    "            return np.where(np.random.random(len(current_position)) < 0.5,\n",
    "                          best_position,\n",
    "                          current_position)\n",
    "    \n",
    "    def fit(self, X, y, classifier):\n",
    "        n_total_features = X.shape[1]\n",
    "        population = np.random.randint(2, size=(self.population_size, n_total_features))\n",
    "        for i in range(self.population_size):\n",
    "            if np.sum(population[i]) < self.n_features:\n",
    "                random_indices = np.random.choice(\n",
    "                    n_total_features, \n",
    "                    self.n_features - np.sum(population[i]),\n",
    "                    replace=False\n",
    "                )\n",
    "                population[i, random_indices] = 1\n",
    "        \n",
    "        global_best_position = None\n",
    "        global_best_fitness = float('-inf')\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            fitness_values = np.array([\n",
    "                self.fitness_function(position, X, y, classifier)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            current_best_idx = np.argmax(fitness_values)\n",
    "            if fitness_values[current_best_idx] > global_best_fitness:\n",
    "                global_best_fitness = fitness_values[current_best_idx]\n",
    "                global_best_position = population[current_best_idx].copy()\n",
    "            \n",
    "            new_population = np.array([\n",
    "                self.honey_badger_movement(position, global_best_position)\n",
    "                for position in population\n",
    "            ])\n",
    "            \n",
    "            population = new_population\n",
    "        \n",
    "        self.best_features = global_best_position\n",
    "        self.best_fitness = global_best_fitness\n",
    "        return self\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    # Read training and testing data\n",
    "    train_data = pd.read_csv('Training Data/PC4_FS_TrainData.csv')\n",
    "    test_data = pd.read_csv('Testing Data/PC4_FS_TestData.csv')\n",
    "    \n",
    "    # Separate features and target for both datasets\n",
    "    X_train = train_data.drop('Defective', axis=1)\n",
    "    y_train = train_data['Defective']\n",
    "    X_test = test_data.drop('Defective', axis=1)\n",
    "    y_test = test_data['Defective']\n",
    "    \n",
    "    # Convert target to numeric\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test, n_features=5):\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Initialize Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Feature selection using training data\n",
    "    print(f\"Starting feature selection at: {time.time()}\")\n",
    "    hb = HoneyBadgerFeatureSelection(n_features_to_select=n_features)\n",
    "    hb.fit(X_train_scaled, y_train, rf)\n",
    "    \n",
    "    # Get selected features\n",
    "    selected_features = np.where(hb.best_features == 1)[0]\n",
    "    selected_feature_names = X_train.columns[selected_features].tolist()\n",
    "    \n",
    "    # Train final model with selected features\n",
    "    X_train_selected = X_train_scaled[:, selected_features]\n",
    "    X_test_selected = X_test_scaled[:, selected_features]\n",
    "    \n",
    "    final_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    final_rf.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = final_rf.predict(X_test_selected)\n",
    "    y_pred_proba = final_rf.predict_proba(X_test_selected)[:, 1]  # For AUC score\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'model': final_rf,\n",
    "        'selected_features': selected_feature_names,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'auc': roc_auc_score(y_test, y_pred_proba),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "        'selected_indices': selected_features,\n",
    "        'feature_importance': final_rf.feature_importances_\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    X_train, X_test, y_train, y_test = load_and_preprocess_data()\n",
    "    \n",
    "    # Train model and get results\n",
    "    results = train_and_evaluate_defect_predictor(X_train, X_test, y_train, y_test, n_features=5)\n",
    "    \n",
    "    # Print selected features and their importance\n",
    "    print(\"\\nSelected Features:\")\n",
    "    for i, (feature, importance) in enumerate(zip(results['selected_features'], \n",
    "                                                results['feature_importance']), 1):\n",
    "        print(f\"{i}. {feature} (Importance: {importance:.4f})\")\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"\\nModel Performance Metrics:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {results['precision']:.4f}\")\n",
    "    print(f\"Recall: {results['recall']:.4f}\")\n",
    "    print(f\"F1-measure: {results['f1']:.4f}\")\n",
    "    print(f\"AUC Score: {results['auc']:.4f}\")\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(results['confusion_matrix'])\n",
    "    \n",
    "    # Feature importance analysis\n",
    "    print(\"\\nFeature Importance Analysis:\")\n",
    "    for feature, idx, importance in zip(results['selected_features'], \n",
    "                                      results['selected_indices'],\n",
    "                                      results['feature_importance']):\n",
    "        print(f\"{feature}: Original index {idx}, Importance {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0997ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
